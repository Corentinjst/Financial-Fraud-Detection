{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "155d8717",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658be8cf",
   "metadata": {},
   "source": [
    "#### 4.1. Load Dataset for Model Training\n",
    "\n",
    "We load the dataset that was previously cleaned and inspected for outliers.\n",
    "This dataset is ready for splitting into features and target for supervised learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59ebb76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"./data/3/df.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44272271",
   "metadata": {},
   "source": [
    "#### 4.2. Define Features and Target\n",
    "\n",
    "- `features` contains all columns except the target variable 'isFraud'.\n",
    "- `target` is the 'isFraud' column, representing whether a transaction is fraudulent.\n",
    "\n",
    "This separation is necessary for supervised machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "162d44d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.drop(columns=\"isFraud\")\n",
    "target = df[\"isFraud\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3e13ef",
   "metadata": {},
   "source": [
    "#### 4.3. Split Data into Train, Validation, and Test Sets\n",
    "\n",
    "We split the dataset into:\n",
    "- Training set: used to train the model\n",
    "- Validation set: used to tune hyperparameters and monitor performance\n",
    "- Test set: used for final evaluation\n",
    "\n",
    "Splitting details:\n",
    "- 3% of data is initially separated into temporary set (`X_temp`) to create validation and test sets.\n",
    "- Stratified splitting ensures that the proportion of fraud and non-fraud cases is preserved in all sets.\n",
    "- Random state is fixed for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bc9e1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(features, target, test_size=0.03, stratify=target, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5228ee1c",
   "metadata": {},
   "source": [
    "#### 4.4. Handle Class Imbalance with Random Under-Sampling\n",
    "\n",
    "Fraud detection datasets are highly imbalanced (fraud cases are rare).\n",
    "We apply RandomUnderSampler to balance the training set:\n",
    "- Reduces the number of non-fraud cases to match the number of fraud cases\n",
    "- Ensures the model does not become biased towards the majority class\n",
    "- Only applied to the training set; validation and test sets remain unchanged\n",
    "\n",
    "Note:\n",
    "- We choose under-sampling instead of techniques like SMOTE because the dataset is very large (21 million rows),\n",
    "  so reducing the majority class still leaves enough data for training.\n",
    "- After under-sampling, the training set contains 53,292 rows, which is sufficient for model learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b50da22",
   "metadata": {},
   "outputs": [],
   "source": [
    "undersampler = RandomUnderSampler(sampling_strategy=\"auto\", random_state=42)\n",
    "X_train, y_train = undersampler.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ccf711c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = X_train.copy()\n",
    "df_train[\"isFraud\"] = y_train\n",
    "\n",
    "df_val = X_val.copy()\n",
    "df_val[\"isFraud\"] = y_val\n",
    "\n",
    "df_test = X_test.copy()\n",
    "df_test[\"isFraud\"] = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507898df",
   "metadata": {},
   "source": [
    "#### 4.5. Verify Distribution in Train, Validation, and Test Sets\n",
    "\n",
    "We print the number of fraud and non-fraud cases in each dataset:\n",
    "- Confirms class distribution after under-sampling\n",
    "- Ensures stratification worked correctly\n",
    "- Helps assess if the dataset is balanced and ready for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66a4b58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "- 53,292 rows\n",
      "- 26,646 fraud cases and 26,646 non-fraud cases\n",
      "- 50.00% fraud, 50.00% non-fraud\n",
      "\n",
      "Validation:\n",
      "- 315,000 rows\n",
      "- 412 fraud cases and 314,588 non-fraud cases\n",
      "- 0.13% fraud, 99.87% non-fraud\n",
      "\n",
      "Test:\n",
      "- 315,000 rows\n",
      "- 412 fraud cases and 314,588 non-fraud cases\n",
      "- 0.13% fraud, 99.87% non-fraud\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, df_set in [(\"Train\", df_train), (\"Validation\", df_val), (\"Test\", df_test)]:\n",
    "    counts = df_set[\"isFraud\"].value_counts()\n",
    "    n_non_fraud = counts.get(0, 0)\n",
    "    n_fraud = counts.get(1, 0)\n",
    "    total_rows = len(df_set)\n",
    "    print(\n",
    "        f\"{name}:\\n\"\n",
    "        f\"- {total_rows:,} rows\\n\"\n",
    "        f\"- {n_fraud:,} fraud cases and {n_non_fraud:,} non-fraud cases\\n\"\n",
    "        f\"- {n_fraud/total_rows:.2%} fraud, {n_non_fraud/total_rows:.2%} non-fraud\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b75fccb",
   "metadata": {},
   "source": [
    "#### 4.6. Save Prepared Datasets\n",
    "\n",
    "We save the train, validation, and test sets as Parquet files:\n",
    "- Makes it easy to reload for model training or evaluation\n",
    "- Preserves data types and structure\n",
    "- Ensures reproducibility of experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9e66ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"./data/4/\", exist_ok=True)\n",
    "\n",
    "df_train.to_parquet(\"./data/4/df_train.parquet\", index=False)\n",
    "df_val.to_parquet(\"./data/4/df_val.parquet\", index=False)\n",
    "df_test.to_parquet(\"./data/4/df_test.parquet\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
