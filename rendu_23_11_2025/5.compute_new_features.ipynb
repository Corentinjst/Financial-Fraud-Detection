{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "256174e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7427b313",
   "metadata": {},
   "source": [
    "#### 5.1. Load Train, Validation, and Test Sets\n",
    "\n",
    "We load the previously prepared datasets from Parquet files.\n",
    "These sets have already been cleaned, split, and balanced, and are ready for feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfc6274b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_parquet(\"./data/4/df_train.parquet\")\n",
    "df_test = pd.read_parquet(\"./data/4/df_test.parquet\")\n",
    "df_val = pd.read_parquet(\"./data/4/df_val.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1f0e25",
   "metadata": {},
   "source": [
    "#### 5.2. Feature Engineering for Transactions\n",
    "\n",
    "The `preprocess_transactions` function generates new features to help the model detect fraud.\n",
    "Features are designed to capture important patterns and behaviors in financial transactions.\n",
    "\n",
    "Types of features created:\n",
    "- **Transaction amount features:** ratios of transaction amount to sender/recipient balances\n",
    "- **Time-based features:** hour, day, weekend/weekday, night, time since last transaction\n",
    "- **Sender/recipient behavior features:** transaction counts, totals, maximum amounts, heavy recipients\n",
    "- **Balance consistency checks:** errors between expected and observed balances\n",
    "- **Transaction type features:** encoded type, type interactions with amount or fraud flags\n",
    "- **Rolling statistics:** moving averages, standard deviations, and maximums over recent transactions\n",
    "\n",
    "These features enrich the dataset with behavioral and temporal patterns that are useful for fraud detection.\n",
    "\n",
    "A progress bar is used to monitor feature calculation.\n",
    "It shows the current feature being calculated and overall progress.\n",
    "This is helpful for large datasets to keep track of long-running preprocessing.\n",
    "\n",
    "Original identifier columns (`nameOrig`, `nameDest`) are dropped to avoid overfitting.\n",
    "Transaction type column (`type`) is one-hot encoded to convert categorical data into numeric format.\n",
    "All remaining columns are ensured to be numeric and clipped to avoid extreme values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae5d3a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_transactions(df):\n",
    "    df = df.sort_values([\"nameOrig\", \"step\"]).reset_index(drop=True)\n",
    "    \n",
    "    new_columns = [\n",
    "        \"delta_sender\", \"delta_recipient\", \"abs_delta_sender\", \"abs_delta_recipient\", \"delta_net\",\n",
    "        \"amount_over_old\", \"amount_over_new\", \"amount_over_total\", \"amount_over_net_balance\",\n",
    "        \"type_encoded\", \"type_times_amount\", \"type_flag_amount\",\n",
    "        \"high_amount_flag\", \"large_tx\", \"hour\", \"day\", \"is_weekend\", \"is_night\", \"sender_receiver_same\",\n",
    "        \"amount_over_mean_sender\", \"sender_tx_count\", \"sender_total_amount\", \"sender_max_amount\", \"amount_over_sender_max\",\n",
    "        \"time_since_last_tx\", \"time_until_next_tx\", \"mean_time_between_tx\", \"time_gap_dev\",\n",
    "        \"recipient_tx_count\", \"recipient_total_received\", \"recipient_heavy\",\n",
    "        \"balance_sender_error\", \"abs_balance_sender_error\", \"balance_recipient_error\", \"abs_balance_recipient_error\", \"balance_error_total\",\n",
    "        \"is_cash\", \"is_transfer\", \"is_logical_inconsistent\",\n",
    "        \"rolling_mean_3\", \"rolling_std_3\", \"rolling_max_3\"\n",
    "    ]\n",
    "    \n",
    "    pbar = tqdm(total=len(new_columns), desc=\"Calculating features\", ncols=120)\n",
    "    \n",
    "    def update(col_name):\n",
    "        pbar.set_postfix_str(f\"Current: {col_name}\")\n",
    "        pbar.update(1)\n",
    "\n",
    "    df[\"delta_sender\"] = df[\"oldbalanceOrg\"] - df[\"newbalanceOrig\"]; update(\"delta_sender\")\n",
    "    df[\"delta_recipient\"] = df[\"newbalanceDest\"] - df[\"oldbalanceDest\"]; update(\"delta_recipient\")\n",
    "    df[\"abs_delta_sender\"] = df[\"delta_sender\"].abs(); update(\"abs_delta_sender\")\n",
    "    df[\"abs_delta_recipient\"] = df[\"delta_recipient\"].abs(); update(\"abs_delta_recipient\")\n",
    "    df[\"delta_net\"] = (df[\"newbalanceOrig\"] - df[\"oldbalanceOrg\"]) + (df[\"newbalanceDest\"] - df[\"oldbalanceDest\"]); update(\"delta_net\")\n",
    "\n",
    "    df[\"amount_over_old\"] = df[\"amount\"] / (df[\"oldbalanceOrg\"] + 1); update(\"amount_over_old\")\n",
    "    df[\"amount_over_new\"] = df[\"amount\"] / (df[\"newbalanceOrig\"] + 1); update(\"amount_over_new\")\n",
    "    df[\"amount_over_total\"] = df[\"amount\"] / (df[\"oldbalanceOrg\"] + df[\"oldbalanceDest\"] + 1); update(\"amount_over_total\")\n",
    "    df[\"amount_over_net_balance\"] = df[\"amount\"] / (df[\"newbalanceOrig\"] + df[\"newbalanceDest\"] + 1); update(\"amount_over_net_balance\")\n",
    "\n",
    "    type_mean = df.groupby(\"type\")[\"isFraud\"].mean()\n",
    "    df[\"type_encoded\"] = df[\"type\"].map(type_mean); update(\"type_encoded\")\n",
    "    df[\"type_times_amount\"] = df[\"type_encoded\"] * df[\"amount\"]; update(\"type_times_amount\")\n",
    "    df[\"type_flag_amount\"] = df[\"type_encoded\"] * df[\"isFlaggedFraud\"] * df[\"amount\"]; update(\"type_flag_amount\")\n",
    "\n",
    "    df[\"high_amount_flag\"] = df[\"isFlaggedFraud\"] * df[\"amount\"]; update(\"high_amount_flag\")\n",
    "    df[\"large_tx\"] = (df[\"amount\"] > 0.5 * df[\"oldbalanceOrg\"]).astype(int); update(\"large_tx\")\n",
    "\n",
    "    df[\"hour\"] = df[\"step\"] % 24; update(\"hour\")\n",
    "    df[\"day\"] = df[\"step\"] // 24; update(\"day\")\n",
    "    df[\"is_weekend\"] = (df[\"day\"] % 7).isin([5,6]).astype(int); update(\"is_weekend\")\n",
    "    df[\"is_night\"] = ((df[\"hour\"] >= 22) | (df[\"hour\"] < 6)).astype(int); update(\"is_night\")\n",
    "\n",
    "    df[\"sender_receiver_same\"] = (df[\"nameOrig\"] == df[\"nameDest\"]).astype(int); update(\"sender_receiver_same\")\n",
    "\n",
    "    grp_sender = df.groupby(\"nameOrig\")[\"amount\"]\n",
    "    df[\"amount_over_mean_sender\"] = df[\"amount\"] / (grp_sender.transform(\"mean\") + 1); update(\"amount_over_mean_sender\")\n",
    "    df[\"sender_tx_count\"] = grp_sender.transform(\"count\"); update(\"sender_tx_count\")\n",
    "    df[\"sender_total_amount\"] = grp_sender.transform(\"sum\"); update(\"sender_total_amount\")\n",
    "    df[\"sender_max_amount\"] = grp_sender.transform(\"max\"); update(\"sender_max_amount\")\n",
    "    df[\"amount_over_sender_max\"] = df[\"amount\"] / (grp_sender.transform(\"max\") + 1); update(\"amount_over_sender_max\")\n",
    "    df[\"time_since_last_tx\"] = df.groupby(\"nameOrig\")[\"step\"].diff().fillna(-1); update(\"time_since_last_tx\")\n",
    "    df[\"time_until_next_tx\"] = df.groupby(\"nameOrig\")[\"step\"].diff(-1).abs().fillna(-1); update(\"time_until_next_tx\")\n",
    "    df[\"mean_time_between_tx\"] = grp_sender.transform(lambda x: x.diff().clip(lower=0).mean()); update(\"mean_time_between_tx\")\n",
    "    df[\"time_gap_dev\"] = df[\"time_since_last_tx\"] - df[\"mean_time_between_tx\"]; update(\"time_gap_dev\")\n",
    "\n",
    "    grp_rec = df.groupby(\"nameDest\")[\"amount\"]\n",
    "    df[\"recipient_tx_count\"] = grp_rec.transform(\"count\"); update(\"recipient_tx_count\")\n",
    "    df[\"recipient_total_received\"] = grp_rec.transform(\"sum\"); update(\"recipient_total_received\")\n",
    "    df[\"recipient_heavy\"] = (df[\"recipient_tx_count\"] > df[\"recipient_tx_count\"].median()).astype(int); update(\"recipient_heavy\")\n",
    "\n",
    "    df[\"balance_sender_error\"] = (df[\"oldbalanceOrg\"] - df[\"amount\"]) - df[\"newbalanceOrig\"]; update(\"balance_sender_error\")\n",
    "    df[\"abs_balance_sender_error\"] = df[\"balance_sender_error\"].abs(); update(\"abs_balance_sender_error\")\n",
    "    df[\"balance_recipient_error\"] = (df[\"oldbalanceDest\"] + df[\"amount\"]) - df[\"newbalanceDest\"]; update(\"balance_recipient_error\")\n",
    "    df[\"abs_balance_recipient_error\"] = df[\"balance_recipient_error\"].abs(); update(\"abs_balance_recipient_error\")\n",
    "    df[\"balance_error_total\"] = df[\"abs_balance_sender_error\"] + df[\"abs_balance_recipient_error\"]; update(\"balance_error_total\")\n",
    "\n",
    "    df[\"is_cash\"] = df[\"type\"].isin([\"CASH_OUT\",\"CASH_IN\"]).astype(int); update(\"is_cash\")\n",
    "    df[\"is_transfer\"] = df[\"type\"].isin([\"TRANSFER\"]).astype(int); update(\"is_transfer\")\n",
    "    df[\"is_logical_inconsistent\"] = ((df[\"oldbalanceOrg\"]==0)&(df[\"amount\"]>0)) | \\\n",
    "                                    (df[\"newbalanceOrig\"]<0) | \\\n",
    "                                    ((df[\"oldbalanceDest\"]==0)&(df[\"amount\"]>0)) | \\\n",
    "                                    (df[\"oldbalanceOrg\"]-df[\"amount\"] != df[\"newbalanceOrig\"]); update(\"is_logical_inconsistent\")\n",
    "\n",
    "    window = 3\n",
    "    df[\"rolling_mean_3\"] = grp_sender.transform(lambda x: x.rolling(window, min_periods=1).mean()); update(\"rolling_mean_3\")\n",
    "    df[\"rolling_std_3\"] = grp_sender.transform(lambda x: x.rolling(window, min_periods=1).std().fillna(0)); update(\"rolling_std_3\")\n",
    "    df[\"rolling_max_3\"] = grp_sender.transform(lambda x: x.rolling(window, min_periods=1).max()); update(\"rolling_max_3\")\n",
    "\n",
    "    df.drop(columns=[\"nameDest\",\"nameOrig\"], inplace=True)\n",
    "    df = pd.get_dummies(df, columns=[\"type\"], drop_first=False)\n",
    "    df = df.select_dtypes(include=\"number\").astype(float)\n",
    "\n",
    "    pbar.close()\n",
    "    return df.clip(-1e10,1e10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ad00b6",
   "metadata": {},
   "source": [
    "#### 5.3. Apply Feature Engineering\n",
    "\n",
    "We apply the preprocessing function to train, validation, and test datasets.\n",
    "This ensures that all datasets have the same features and are ready for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39f3da89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating features: 100%|█████████████████████████████████████| 42/42 [00:52<00:00,  1.25s/it, Current: rolling_max_3]\n",
      "Calculating features: 100%|█████████████████████████████████████| 42/42 [04:41<00:00,  6.71s/it, Current: rolling_max_3]\n",
      "Calculating features: 100%|█████████████████████████████████████| 42/42 [06:22<00:00,  9.11s/it, Current: rolling_max_3]\n"
     ]
    }
   ],
   "source": [
    "df_train = preprocess_transactions(df_train)\n",
    "df_test = preprocess_transactions(df_test)\n",
    "df_val = preprocess_transactions(df_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ec38e0",
   "metadata": {},
   "source": [
    "#### 5.4. Save Preprocessed Datasets\n",
    "\n",
    "The newly engineered datasets are saved as Parquet files for future use:\n",
    "- Preserves all calculated features\n",
    "- Ensures reproducibility\n",
    "- Ready for model training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "510d7120",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"./data/5/\", exist_ok=True)\n",
    "\n",
    "df_train.to_parquet(\"./data/5/df_train.parquet\", index=False)\n",
    "df_val.to_parquet(\"./data/5/df_val.parquet\", index=False)\n",
    "df_test.to_parquet(\"./data/5/df_test.parquet\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
